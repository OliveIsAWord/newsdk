//
// Inline preprocessor for the lexer.
//

#INCLUDE "<inc>/Lexer.hjk"

CONST LEX_DIRECTIVE_MAX := 64

LexDirectiveBuffer : UBYTE[LEX_DIRECTIVE_MAX]

LexDirectiveHashTable : TlHashTable

FNPTR LexDirectiveParseF ()

STRUCT LexDirective
    Entry : TlHashTableEntry, // MUST be at the start
    ParseRoutine : LexDirectiveParseF,
END

LexDirectiveBumpArray : LexDirective[16]
LexDirectiveBumpIndex := 0

FN LexDirectiveInsert (
    IN name : ^UBYTE,
    IN parsefunc : LexDirectiveParseF,
)

    // Insert the directive into the directive hash table.
    // This is done every time the compiler is invoked so it should be VERY
    // fast. To this end we completely avoid dynamic allocation with this silly
    // directive structure bump allocator. The hash table package does no
    // dynamic allocation, nor does it do any string copies (though it does
    // iterate the string to calculate the hash), so this should all be quite
    // speedy.

    directive := &LexDirectiveBumpArray[LexDirectiveBumpIndex]
    LexDirectiveBumpIndex += 1

    directive^.ParseRoutine = parsefunc

    TlInsertHashTable (
        &LexDirectiveHashTable, // hashtable
        &directive^.Entry, // entry
        name, // key
    )
END

FN LexPreprocessorInit ()

    TlInitializeHashTable ( &LexDirectiveHashTable )

    LexDirectiveInsert ( "INCLUDE", &LexParseInclude )
    LexDirectiveInsert ( "DEFINE", &LexParseDefine )
    LexDirectiveInsert ( "MACRO", &LexParseMacro )
    LexDirectiveInsert ( "IF", &LexParseIf )
    LexDirectiveInsert ( "ELSE", &LexParseElse )
    LexDirectiveInsert ( "ELSEIF", &LexParseElseif )
    LexDirectiveInsert ( "END", &LexParseEnd )
END

FN LexParseDirective ()

    // The lexer found a preprocessor directive and called us to handle it.
    // Until we return, we are in full control of the source stream, and can
    // consume it, tokenize it, etc to our hearts content. Thanks to the
    // layered nature of the lexer, we don't have to worry about maintaining
    // line numbers and so on.

    // Declare a token stub for error reporting purposes.

    token : LexToken

    LexCollectDirectiveToken (
        &token, // token
        &LexDirectiveBuffer[0], // buffer
    )

    directive := CAST TlLookupHashTable (
        &LexDirectiveHashTable, // hashtable
        &LexDirectiveBuffer[0], // key
    ) TO ^LexDirective

    IF NOT directive THEN
        LexTokenError ( &token, "Unknown directive", 0, 0, 0 )
    END

    directive^.ParseRoutine ()
END

FN LexNextNonWhitespaceCharacter (
    IN token : ^LexToken,
) : UBYTE

    // Capture the stream position information in the stub token, for error
    // reporting.

    stream := LexCurrentStream

    IF stream THEN
        token^.FileBlock = stream^.FileBlock
        token^.LineNumber = stream^.LineNumber
        token^.LinePosition = stream^.LinePosition
    END

    byte := LexStreamNextCharacter ()

    // Skip any leading whitespace.

    WHILE LexCharTreatment[byte] == CHAR_WHITESPACE DO
        stream = LexCurrentStream

        IF stream THEN
            token^.FileBlock = stream^.FileBlock
            token^.LineNumber = stream^.LineNumber
            token^.LinePosition = stream^.LinePosition
        END

        byte = LexStreamNextCharacter ()
    END

    IF byte == 0 THEN
        LexStreamError ( "Unexpected EOF while parsing directive", 0, 0, 0 )
    END

    RETURN byte
END

FN LexCollectDirectiveToken (
    IN token : ^LexToken,
    IN buffer : ^UBYTE,
)

    // Collect a simple token, terminated by whitespace.

    byte := LexNextNonWhitespaceCharacter ( token )
    len := 0

    WHILE LexCharTreatment[byte] != CHAR_WHITESPACE DO
        IF len == LEX_DIRECTIVE_MAX - 1 THEN
            LexTokenError ( token, "Directive length too great.", 0, 0, 0 )
        END

        buffer^ = byte
        buffer += 1
        len += 1

        byte = LexStreamNextCharacter ()
    END

    buffer^ = 0
END

FN LexGetPreprocessorString (
    IN token : ^LexToken,
    IN buffer : ^TlDynamicBuffer,
)

    // Collect a simple string. All we do is read the contents of the string,
    // as-is, directly into the dynamic buffer. The only thing we care about is
    // to ignore double-quotes that are directly preceded by a backslash, but we
    // still pass the backslash up. The first double-quote not preceded by a
    // backslash terminates the string.

    backslash := FALSE

    WHILE TRUE DO
        byte := LexStreamNextCharacter ()

        IF byte == 0 THEN
            LexTokenError ( token,
                "Unexpected EOF while parsing string", 0, 0, 0 )
        END

        IF byte == '\"' AND NOT backslash THEN
            LEAVE
        END

        TlInsertDynamicBuffer (
            buffer, // array
            byte, // byte
        )

        IF backslash THEN
            backslash = FALSE

            CONTINUE
        END

        backslash = byte == '\\'
    END
END

FN LexCollectString (
    IN token : ^LexToken,
    IN buffer : ^TlDynamicBuffer,
)

    // Collect a string token for internal preprocessor usage, such as for the
    // INCLUDE directive.

    byte := LexNextNonWhitespaceCharacter ( token )

    IF byte != '\"' THEN
        LexTokenError ( token, "Expected a string", 0, 0, 0 )
    END

    LexGetPreprocessorString (
        token, // token
        buffer, // buffer
    )

    // Insert null terminator, since that wasn't done already.

    TlInsertDynamicBuffer (
        buffer, // array
        0, // byte
    )
END

FN LexGetComplexString (
    IN token : ^LexToken,
    IN buffer : ^TlDynamicBuffer,
)

    // Collect a complex string into the provided dynamic buffer, which will be
    // terminated by a close bracket. Our job is complicated by the following
    // factors:
    //
    //  o We have to make sure that we count the number of open brackets that we
    //    encounter, otherwise we will mistakenly terminate this complex string
    //    if we come across, for instance, an array index.
    //
    //  o We have to track whether we're in a string, or a character literal,
    //    so that a close bracket character within the string doesn't cause us
    //    to mistakenly exit.
    //
    //  o We have to track whether we're in a comment, for the same reason.

    TlInternalError ( "TODO parse complex string", 0, 0, 0 )
END

FN LexCollectValue (
    IN token : ^LexToken,
    IN buffer : ^TlDynamicBuffer,
)

    // Collect a preprocessor value. This will be one of the following forms in
    // the source text; all of these cases will be presented to the caller as a
    // string in a dynamic buffer:
    //
    //  MACRO               The name of a macro. It will be expanded in-place.
    //
    //  "STRING"            The contents of a literal string. The enclosing
    //                      quotes will be considered part of the string.
    //
    //  [CMPLX STRING]      The contents of a complex string, which may be any
    //                      un-escaped section of Jackal code, including
    //                      preprocessor expressions, etc. Another difference is
    //                      that the brackets are NOT considered part of the
    //                      string.
    //
    //  (OP val1 val2 ...)  An expression yielding some kind of value.
    //
    //  None of above       Will be returned as a single whitespace-terminated
    //                      token.

    byte := LexNextNonWhitespaceCharacter ( token )

    IF byte == '\"' THEN
        TlInsertDynamicBuffer (
            buffer, // array
            '\"', // byte
        )

        LexGetPreprocessorString (
            token, // token
            buffer, // buffer
        )

        TlInsertDynamicBuffer (
            buffer, // array
            '\"', // byte
        )

        TlInsertDynamicBuffer (
            buffer, // array
            0, // byte
        )

        LEAVE

    ELSEIF byte == '[' THEN
        LexGetComplexString (
            token, // token
            buffer, // buffer
        )

        TlInsertDynamicBuffer (
            buffer, // array
            0, // byte
        )

        LEAVE

    ELSEIF byte == '(' THEN
        // This is an expression. Collect the operator, look it up in the hash
        // table, and call the correct parse function for the operator. It will
        // consume the close parenthesis.

        LEAVE
    END

    // This either matches with a macro name, or doesn't. Only non-function
    // macros are permitted. If it matches, we expand in place by adding it to
    // the top of the stream stack and looping. If it doesn't match, we just
    // return this token.
END

FN LexParseInclude ()

    // Parse the include statement. We just have to consume a string. Then we
    // construct a path depending on what the prefix is, if any. Prefixes are:
    //
    //  [none]  Relative to the directory containing the source file.
    //  <inc>/  Relative to the set of incdirs provided in the command line.
    //  <ll>/   Relative to the set of libdirs provided, which may include
    //          a system library as appended by the host specific part of the
    //          compiler.
    //
    // If we find the exact include path string in the hash set of included
    // files, then ignore this directive.
    //
    // After we find and open a matching file, we bump-allocate a file block,
    // and initialize it to contain the path string, and the opened handle.
    // Then we create a file stream based on this file block, and add it to the
    // top of the stream stack, causing the rest of the lexer to consume tokens
    // from that file until it reaches EOF.

    str : TlDynamicBuffer
    token : LexToken

    TlInitializeDynamicBuffer ( &str )

    LexCollectString (
        &token, // token
        &str, // buffer
    )

    IF LexFalseCount THEN
        // We're in a region that is being conditionally compiled out, so
        // do nothing except collect that string from the source stream.

        TlUninitializeDynamicBuffer ( &str )

        LEAVE
    END

    // Get a file block for the include string. We'll fill it in with the file
    // path in a second.

    created : UBYTE

    fileblock := FeCreateFileBlock (
        str.Buffer, // includename
        &created, // OUT created
    )

    IF NOT created THEN
        // This file has already been included!

        TlUninitializeDynamicBuffer ( &str )

        LEAVE
    END

    // Figure out the file path.

    filepath : TlDynamicBuffer

    TlInitializeDynamicBuffer ( &filepath )

    handle : ^VOID
    found := FALSE

    IF TlCompareStringWithMax ( str.Buffer, "<inc>/", 6 ) == 0 THEN
        // Relative to the first matching include directory.

        found = TlMatchPath (
            &str.Buffer[6], // path
            &FeIncludeDirectory, // pathset
            &filepath, // resultingpath
            &handle, // OUT handle
        )

    ELSEIF TlCompareStringWithMax ( str.Buffer, "<ll>/", 5 ) == 0 THEN
        // Relative to the first matching library directory.

        found = TlMatchPath (
            &str.Buffer[5], // path
            &FeLibraryDirectory, // pathset
            &filepath, // resultingpath
            &handle, // OUT handle
        )

    ELSE
        // Relative to the current source file's parent directory.

        TlCopyParentPath (
            &LexCurrentStream^.FileBlock^.FilePath, // srcpath
            &filepath, // destpath
        )

        IF filepath.Buffer[filepath.Count - 1] != '/' THEN
            TlInsertDynamicBuffer ( &filepath, '/' )
        END

        TlCopyIntoDynamicBuffer (
            &filepath, // array
            str.Buffer, // srcbuf
            str.Count, // length
        )

        TlInsertDynamicBuffer ( &filepath, 0 )

        status := TlOpenSource (
            filepath.Buffer, // filename
            &handle, // OUT handle
        )

        IF NOT status THEN
            found = TRUE
        END
    END

    IF NOT found THEN
        LexTokenError ( &token, "Failed to include the file.", 0, 0, 0 )
    END

    // Copy the file path into the fileblock.

    FeCopyPathFileBlock (
        fileblock, // fileblock
        filepath.Buffer, // filepath
    )

    TlUninitializeDynamicBuffer ( &filepath )
    TlUninitializeDynamicBuffer ( &str )

    // Create a new file stream.

    stream := LexCreateFileStream (
        fileblock, // fileblock
        handle, // handle
    )

    // Add it to the stream stack to cause further characters to be consumed
    // from this file. It will be popped back off, resuming the previous file,
    // when EOF is reached.

    LexPushStream ( stream )
END

FN LexParseDefine ()

    // This directive defines a simple macro (as opposed to a function macro).
    // First we consume the name token, then we consume the contents.

    LexStreamError ( "TODO define", 0, 0, 0 )
END

FN LexParseMacro ()

    LexStreamError ( "TODO macro", 0, 0, 0 )
END

FN LexParseIf ()

    LexStreamError ( "TODO if", 0, 0, 0 )
END

FN LexParseElse ()

    LexStreamError ( "TODO else", 0, 0, 0 )
END

FN LexParseElseif ()

    LexStreamError ( "TODO elseif", 0, 0, 0 )
END

FN LexParseEnd ()

    LexStreamError ( "TODO end", 0, 0, 0 )
END