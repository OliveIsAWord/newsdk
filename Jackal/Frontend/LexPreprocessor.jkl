//
// Inline preprocessor for the lexer.
//

#INCLUDE "<inc>/Lexer.hjk"

LexDirectiveHashTable : TlHashTable
LexOperatorHashTable : TlHashTable
LexIfStack : TlDynamicBuffer

FNPTR LexDirectiveParseF ()

FNPTR LexOperatorParseF (
    IN buffer : ^TlDynamicBuffer,
)

STRUCT LexDirective
    Entry : TlHashTableEntry, // MUST be at the start
    ParseRoutine : LexDirectiveParseF,
END

STRUCT LexOperator
    Entry : TlHashTableEntry, // MUST be at the start
    ParseRoutine : LexOperatorParseF,
END

LexDirectiveBumpArray : LexDirective[16]
LexDirectiveBumpIndex := 0

FN LexInsertDirective (
    IN name : ^UBYTE,
    IN parsefunc : LexDirectiveParseF,
)

    // Insert the directive into the directive hash table.
    // This is done every time the compiler is invoked so it should be VERY
    // fast. To this end we completely avoid dynamic allocation with this silly
    // directive structure bump allocator. The hash table package does no
    // dynamic allocation, nor does it do any string copies (though it does
    // iterate the string to calculate the hash), so this should all be quite
    // speedy.

    directive := &LexDirectiveBumpArray[LexDirectiveBumpIndex]
    LexDirectiveBumpIndex += 1

    directive^.ParseRoutine = parsefunc

    TlInsertHashTable (
        &LexDirectiveHashTable, // hashtable
        &directive^.Entry, // entry
        name, // key
    )
END

LexOperatorBumpArray : LexOperator[32]
LexOperatorBumpIndex := 0

FN LexInsertOperator (
    IN name : ^UBYTE,
    IN parsefunc : LexOperatorParseF,
)

    operator := &LexOperatorBumpArray[LexOperatorBumpIndex]
    LexOperatorBumpIndex += 1

    operator^.ParseRoutine = parsefunc

    TlInsertHashTable (
        &LexOperatorHashTable, // hashtable
        &operator^.Entry, // entry
        name, // key
    )
END

FN LexPreprocessorInit ()

    TlInitializeHashTable ( &LexDirectiveHashTable )
    TlInitializeDynamicBuffer ( &LexIfStack )

    LexInsertDirective ( "INCLUDE", &LexParseInclude )
    LexInsertDirective ( "DEFINE", &LexParseDefine )
    LexInsertDirective ( "MACRO", &LexParseMacro )
    LexInsertDirective ( "IF", &LexParseIf )
    LexInsertDirective ( "ELSE", &LexParseElse )
    LexInsertDirective ( "ELSEIF", &LexParseElseif )
    LexInsertDirective ( "END", &LexParseEnd )
    LexInsertDirective ( "UNDEFINE", &LexParseUndefine )

    LexInsertOperator ( "==", &LexOperatorEquals )
    LexInsertOperator ( "<=", &LexOperatorLteq )
    LexInsertOperator ( ">=", &LexOperatorGteq )
    LexInsertOperator ( "!=", &LexOperatorNeq )
    LexInsertOperator ( "+", &LexOperatorAdd )
    LexInsertOperator ( "-", &LexOperatorSub )
    LexInsertOperator ( "*", &LexOperatorMul )
    LexInsertOperator ( "/", &LexOperatorDiv )
    LexInsertOperator ( "<<", &LexOperatorLsh )
    LexInsertOperator ( ">>", &LexOperatorRsh )
    LexInsertOperator ( "strcat", &LexOperatorStrcat )
    LexInsertOperator ( "strcmp", &LexOperatorStrcmp )
    LexInsertOperator ( "not", &LexOperatorNot )
    LexInsertOperator ( "~", &LexOperatorBitNot )
    LexInsertOperator ( "|", &LexOperatorBitOr )
    LexInsertOperator ( "$", &LexOperatorBitXor )
    LexInsertOperator ( "&", &LexOperatorBitAnd )
END

FN LexParseDirective ()

    // The lexer found a preprocessor directive and called us to handle it.
    // Until we return, we are in full control of the source stream, and can
    // consume it, tokenize it, etc to our hearts content. Thanks to the
    // layered nature of the lexer, we don't have to worry about maintaining
    // line numbers and so on.

    // Declare a token stub for error reporting purposes.

    token : LexToken
    buffer : UBYTE[LEX_DIRECTIVE_MAX]

    LexCollectDirectiveToken (
        &token, // token
        &buffer[0], // buffer
    )

    directive := CAST TlLookupHashTable (
        &LexDirectiveHashTable, // hashtable
        &buffer[0], // key
    ) TO ^LexDirective

    IF NOT directive THEN
        LexTokenError ( &token, "Unknown directive", 0, 0, 0 )
    END

    directive^.ParseRoutine ()
END

FN LexNextNonWhitespaceCharacter (
    IN token : ^LexToken,
) : UBYTE

    // Capture the stream position information in the stub token, for error
    // reporting.

    stream := LexCurrentStream

    IF stream THEN
        token^.FileBlock = stream^.FileBlock
        token^.LineNumber = stream^.LineNumber
        token^.LinePosition = stream^.LinePosition
    END

    byte := LexStreamNextCharacter ()

    // Skip any leading whitespace.

    WHILE LexCharTreatment[byte] == CHAR_WHITESPACE DO
        stream = LexCurrentStream

        IF stream THEN
            token^.FileBlock = stream^.FileBlock
            token^.LineNumber = stream^.LineNumber
            token^.LinePosition = stream^.LinePosition
        END

        byte = LexStreamNextCharacter ()
    END

    IF byte == 0 THEN
        LexStreamError ( "Unexpected EOF while parsing directive", 0, 0, 0 )
    END

    RETURN byte
END

FN LexCollectDirectiveToken (
    IN token : ^LexToken,
    IN buffer : ^UBYTE,
)

    // Collect a simple token, terminated by whitespace.

    byte := LexNextNonWhitespaceCharacter ( token )
    len := 0

    WHILE LexCharTreatment[byte] != CHAR_WHITESPACE DO
        IF len == LEX_DIRECTIVE_MAX - 1 THEN
            LexTokenError ( token, "Directive length too great.", 0, 0, 0 )
        END

        buffer^ = byte
        buffer += 1
        len += 1

        byte = LexStreamNextCharacter ()
    END

    buffer^ = 0
END

FN LexGetPreprocessorString (
    IN token : ^LexToken,
    IN buffer : ^TlDynamicBuffer,
)

    // Collect a simple string. All we do is read the contents of the string,
    // as-is, directly into the dynamic buffer. The only thing we care about is
    // to ignore double-quotes that are directly preceded by a backslash, but we
    // still pass the backslash up. The first double-quote not preceded by a
    // backslash terminates the string.

    backslash := FALSE

    WHILE TRUE DO
        byte := LexStreamNextCharacter ()

        IF byte == 0 THEN
            LexTokenError ( token,
                "Unexpected EOF while parsing string", 0, 0, 0 )
        END

        IF byte == '\"' AND NOT backslash THEN
            LEAVE
        END

        TlInsertDynamicBuffer (
            buffer, // array
            byte, // byte
        )

        IF backslash THEN
            backslash = FALSE

            CONTINUE
        END

        backslash = byte == '\\'
    END
END

FN LexCollectString (
    IN token : ^LexToken,
    IN buffer : ^TlDynamicBuffer,
)

    // Collect a string token for internal preprocessor usage, such as for the
    // INCLUDE directive.

    byte := LexNextNonWhitespaceCharacter ( token )

    IF byte != '\"' THEN
        LexTokenError ( token, "Expected a string", 0, 0, 0 )
    END

    LexGetPreprocessorString (
        token, // token
        buffer, // buffer
    )

    // Insert null terminator, since that wasn't done already.

    TlInsertDynamicBuffer (
        buffer, // array
        0, // byte
    )
END

FN LexGetComplexString (
    IN token : ^LexToken,
    IN buffer : ^TlDynamicBuffer,
)

    // Collect a complex string into the provided dynamic buffer, which will be
    // terminated by a close bracket. Our job is complicated by the following
    // factors:
    //
    //  o We have to make sure that we count the number of open brackets that we
    //    encounter, otherwise we will mistakenly terminate this complex string
    //    if we come across, for instance, an array index.
    //
    //  o We have to track whether we're in a string, or a character literal,
    //    so that a close bracket character within the string doesn't cause us
    //    to mistakenly exit.
    //
    //  o We have to track whether we're in a comment, for the same reason.

    bracketdepth := 1
    comment := FALSE
    backslash := FALSE
    instring := FALSE
    inliteral := FALSE
    sawforwardslash := FALSE

    WHILE TRUE DO
        byte := LexStreamNextCharacter ()

        IF byte == 0 THEN
            LexTokenError ( token, "Unexpected EOF while parsing string", 0, 0, 0 )
        END

        IF comment THEN
            IF byte == '\n' THEN
                comment = FALSE
            ELSE
                CONTINUE
            END
        ELSEIF byte != '/' THEN
            sawforwardslash = FALSE
        END

        IF backslash THEN
            backslash = FALSE

        ELSEIF byte == '\\' THEN
            backslash = TRUE

        ELSEIF instring THEN
            instring = NOT (byte == '\"')

        ELSEIF inliteral THEN
            inliteral = NOT (byte == 0x27) // single-quote

        ELSEIF byte == '/' THEN
            IF sawforwardslash THEN
                sawforwardslash = FALSE
                comment = TRUE
            ELSE
                sawforwardslash = TRUE
            END

        ELSEIF byte == '\"' THEN
            instring = TRUE

        ELSEIF byte == 0x27 THEN // single-quote
            inliteral = TRUE

        ELSEIF byte == '[' THEN
            bracketdepth += 1

        ELSEIF byte == ']' THEN
            bracketdepth -= 1

            IF bracketdepth == 0 THEN
                // Break out now so that we don't include the close bracket in
                // the string buffer.

                BREAK
            END
        END

        TlInsertDynamicBuffer (
            buffer, // array
            byte, // byte
        )
    END
END

FN LexCollectValue (
    IN token : ^LexToken,
    IN buffer : ^TlDynamicBuffer,
)

    // Collect a preprocessor value. This will be one of the following forms in
    // the source text; all of these cases will be presented to the caller as a
    // string in a dynamic buffer:
    //
    //  MACRO               The name of a macro. It will be expanded in-place.
    //
    //  "STRING"            The contents of a literal string. The enclosing
    //                      quotes will be considered part of the string.
    //
    //  [CMPLX STRING]      The contents of a complex string, which may be any
    //                      un-escaped section of Jackal code, including
    //                      preprocessor expressions, etc. Another difference is
    //                      that the brackets are NOT considered part of the
    //                      string.
    //
    //  (OP val1 val2 ...)  An expression yielding some kind of value.
    //
    //  None of above       Will be returned as a single whitespace-terminated
    //                      token.

    byte := LexNextNonWhitespaceCharacter ( token )

    IF byte == '\"' THEN
        TlInsertDynamicBuffer (
            buffer, // array
            '\"', // byte
        )

        LexGetPreprocessorString (
            token, // token
            buffer, // buffer
        )

        TlInsertDynamicBuffer (
            buffer, // array
            '\"', // byte
        )

        TlInsertDynamicBuffer (
            buffer, // array
            0, // byte
        )

        LEAVE

    ELSEIF byte == '[' THEN
        LexGetComplexString (
            token, // token
            buffer, // buffer
        )

        TlInsertDynamicBuffer (
            buffer, // array
            0, // byte
        )

        LEAVE

    ELSEIF byte == '(' THEN
        // This is an expression. Collect the operator, look it up in the hash
        // table, and call the correct parse function for the operator. It will
        // consume the close parenthesis.

        opbuffer : UBYTE[LEX_DIRECTIVE_MAX]
        optoken : LexToken

        LexCollectDirectiveToken (
            &optoken, // token
            &opbuffer[0], // buffer
        )

        operator := CAST TlLookupHashTable (
            &LexOperatorHashTable, // hashtable
            &opbuffer[0], // key
        ) TO ^LexOperator

        IF NOT operator THEN
            LexTokenError ( &optoken, "Unknown operator", 0, 0, 0 )
        END

        operator^.ParseRoutine ( buffer )

        LEAVE
    END

    // Collect this as a simple token, terminated by whitespace.

    TlInsertDynamicBuffer (
        buffer, // array
        byte, // byte
    )

    byte = LexStreamNextCharacter ()

    WHILE LexCharTreatment[byte] != CHAR_WHITESPACE DO
        IF byte == 0 THEN
            LexTokenError ( token, "Unexpected EOF", 0, 0, 0 )
        END

        TlInsertDynamicBuffer (
            buffer, // array
            byte, // byte
        )

        byte = LexStreamNextCharacter ()
    END

    TlInsertDynamicBuffer (
        buffer, // array
        0, // byte
    )

    // This either matches with a macro name, or doesn't. Only non-function
    // macros are permitted. If it matches, we expand in place by adding it to
    // the top of the stream stack and looping. If it doesn't match, we just
    // return this token.

END

FN LexCollectValueNumeric (
    IN token : ^LexToken,
) : ULONG

    buffer : TlDynamicBuffer

    TlInitializeDynamicBuffer ( &buffer )

    LexCollectValue (
        token, // token
        &buffer, // buffer
    )

    IF buffer.Buffer[0] < '0' OR buffer.Buffer[0] > '9' THEN
        LexTokenError ( token, "Expected numeric value", 0, 0, 0 )
    END

    num := LexCrunchNumber (
        token, // token
        &buffer.Buffer[0], // buffer
    )

    TlUninitializeDynamicBuffer ( &buffer )

    RETURN num
END

FN LexConsumeCloseParenthesis ()

    token : LexToken

    byte := LexNextNonWhitespaceCharacter ( &token )

    IF byte != ')' THEN
        LexTokenError ( &token, "Expected close parenthesis", 0, 0, 0 )
    END
END

FN (LexDirectiveParseF) LexParseInclude ()

    // Parse the include statement. We just have to consume a string. Then we
    // construct a path depending on what the prefix is, if any. Prefixes are:
    //
    //  [none]  Relative to the directory containing the source file.
    //  <inc>/  Relative to the set of incdirs provided in the command line.
    //  <ll>/   Relative to the set of libdirs provided, which may include
    //          a system library as appended by the host specific part of the
    //          compiler.
    //
    // If we find the exact include path string in the hash set of included
    // files, then ignore this directive.
    //
    // After we find and open a matching file, we bump-allocate a file block,
    // and initialize it to contain the path string, and the opened handle.
    // Then we create a file stream based on this file block, and add it to the
    // top of the stream stack, causing the rest of the lexer to consume tokens
    // from that file until it reaches EOF.

    str : TlDynamicBuffer
    token : LexToken

    TlInitializeDynamicBuffer ( &str )

    LexCollectString (
        &token, // token
        &str, // buffer
    )

    IF LexFalseCount THEN
        // We're in a region that is being conditionally compiled out, so
        // do nothing except collect that string from the source stream.

        TlUninitializeDynamicBuffer ( &str )

        LEAVE
    END

    // Get a file block for the include string. We'll fill it in with the file
    // path in a second.

    created : UBYTE

    fileblock := FeCreateFileBlock (
        str.Buffer, // includename
        &created, // OUT created
    )

    IF NOT created THEN
        // This file has already been included!

        TlUninitializeDynamicBuffer ( &str )

        LEAVE
    END

    // Figure out the file path.

    filepath : TlDynamicBuffer

    TlInitializeDynamicBuffer ( &filepath )

    handle : ^VOID
    found := FALSE

    IF TlCompareStringWithMax ( str.Buffer, "<inc>/", 6 ) == 0 THEN
        // Relative to the first matching include directory.

        found = TlMatchPath (
            &str.Buffer[6], // path
            &FeIncludeDirectory[0], // pathset
            &filepath, // resultingpath
            &handle, // OUT handle
        )

    ELSEIF TlCompareStringWithMax ( str.Buffer, "<ll>/", 5 ) == 0 THEN
        // Relative to the first matching library directory.

        found = TlMatchPath (
            &str.Buffer[5], // path
            &FeLibraryDirectory[0], // pathset
            &filepath, // resultingpath
            &handle, // OUT handle
        )

    ELSE
        // Relative to the current source file's parent directory.

        TlCopyParentPath (
            &LexCurrentStream^.FileBlock^.FilePath[0], // srcpath
            &filepath, // destpath
        )

        IF filepath.Buffer[filepath.Count - 1] != '/' THEN
            TlInsertDynamicBuffer (
                &filepath, // array
                '/', // byte
            )
        END

        TlCopyIntoDynamicBuffer (
            &filepath, // array
            str.Buffer, // srcbuf
            str.Count, // length
        )

        TlInsertDynamicBuffer (
            &filepath, // array
            0, // byte
        )

        status := TlOpenSource (
            filepath.Buffer, // filename
            &handle, // OUT handle
        )

        IF NOT status THEN
            found = TRUE
        END
    END

    IF NOT found THEN
        LexTokenError ( &token, "Failed to include the file.", 0, 0, 0 )
    END

    // Copy the file path into the fileblock.

    FeCopyPathFileBlock (
        fileblock, // fileblock
        filepath.Buffer, // filepath
    )

    TlUninitializeDynamicBuffer ( &filepath )
    TlUninitializeDynamicBuffer ( &str )

    // Create a new file stream.

    stream := LexCreateFileStream (
        fileblock, // fileblock
        handle, // handle
    )

    // Add it to the stream stack to cause further characters to be consumed
    // from this file. It will be popped back off, resuming the previous file,
    // when EOF is reached.

    LexPushStream ( stream )
END

FN (LexDirectiveParseF) LexParseDefine ()

    // This directive defines a simple macro (as opposed to a function macro).
    // First we consume the name token, then we consume the contents.

    IF LexFalseCount THEN
        // Nevermind, we are being compiled out! Just eat the name and contents
        // and return.

        namebuffer : UBYTE[LEX_DIRECTIVE_MAX]
        contentsbuffer : TlDynamicBuffer
        trashtoken : LexToken

        TlInitializeDynamicBuffer ( &contentsbuffer )

        LexCollectDirectiveToken (
            &trashtoken, // token
            &namebuffer[0], // buffer
        )

        LexCollectValue (
            &trashtoken, // token
            &contentsbuffer, // buffer
        )

        TlUninitializeDynamicBuffer ( &contentsbuffer )

        LEAVE
    END

    macro : ^LexMacro

    status := TlBumpAlloc (
        SIZEOF LexMacro, // bytes
        &macro, // OUT ptr
    )

    IF status THEN
        TlInternalError ( "Failed to allocate macro", 0, 0, 0 )
    END

    LexCollectDirectiveToken (
        &macro^.NameToken, // token
        &macro^.Name[0], // buffer
    )

    oldmacro := CAST TlLookupSymbolTable (
        LexCurrentMacroScope, // symboltable
        &macro^.Name[0], // name
    ) TO ^LexMacro

    IF oldmacro THEN
        LexTokenError ( &macro^.NameToken, "Macro already defined", 0, 0, 0 )
    END

    macro^.IsFunctionMacro = FALSE

    LexCollectValue (
        &macro^.NameToken, // token
        &macro^.Contents, // buffer
    )

    TlInsertSymbolTable (
        LexCurrentMacroScope, // symboltable
        &macro^.Entry, // entry
        &macro^.Name[0], // name
    )
END

FN (LexDirectiveParseF) LexParseUndefine ()

    buffer : UBYTE[LEX_DIRECTIVE_MAX]
    token : LexToken

    LexCollectDirectiveToken (
        &token, // token
        &buffer[0], // buffer
    )

    IF LexFalseCount THEN
        // We're being compiled out, just return.

        LEAVE
    END

    oldmacro := CAST TlLookupSymbolTable (
        LexCurrentMacroScope, // symboltable
        &buffer[0], // name
    ) TO ^LexMacro

    IF NOT oldmacro THEN
        // Wasn't defined anyway.

        LEAVE
    END

    // Remove the macro from the symbol table.

    TlRemoveSymbolTable (
        CAST oldmacro TO ^TlHashTableEntry, // entry
    )
END

CONST ARG_NAME_NONZERO : UBYTE = 1
CONST ARG_NAME_DONE : UBYTE = 2

FN LexCollectMacroDefArgName (
    IN token : ^LexToken,
    IN buffer : ^UBYTE,
) : UBYTE

    // Collect a token, terminated by comma, whitespace, or close parenthesis.
    // Return whether or not it was terminated by a close parenthesis.

    byte : UBYTE
    len := 0

    WHILE TRUE DO
        byte = LexNextNonWhitespaceCharacter ( token )

        IF byte == ')' THEN
            RETURN ARG_NAME_DONE
        ELSEIF byte == ',' THEN
            CONTINUE
        END

        BREAK
    END

    WHILE TRUE DO
        IF LexCharTreatment[byte] == CHAR_WHITESPACE THEN
            buffer^ = 0

            RETURN ARG_NAME_NONZERO
        END

        IF byte == ')' THEN
            buffer^ = 0

            RETURN ARG_NAME_NONZERO | ARG_NAME_DONE
        END

        IF byte == ',' THEN
            buffer^ = 0

            RETURN ARG_NAME_NONZERO
        END

        IF LexCharTreatment[byte] != CHAR_NORMAL THEN
            LexTokenError ( token, "Illegal character in arg name", 0, 0, 0 )
        END

        IF len == LEX_DIRECTIVE_MAX - 1 THEN
            LexTokenError ( token, "Directive length too great.", 0, 0, 0 )
        END

        buffer^ = byte
        buffer += 1
        len += 1

        byte = LexStreamNextCharacter ()
    END
END

FN LexCollectMacroDefArgList (
    IN ignore : UBYTE,
    OUT arglisthead : ^^LexMacroArgument,
    OUT length : ^ULONG,
)

    token : LexToken
    buffer : UBYTE[LEX_DIRECTIVE_MAX]
    hashtable : TlHashTable
    arglisttail : ^LexMacroArgument = NULLPTR

    // Use a hash set to determine if the user illegally uses an argument name
    // twice.

    TlInitializeHashTable ( &hashtable )

    arglisthead^ = NULLPTR
    length^ = 0

    WHILE TRUE DO
        state := LexCollectMacroDefArgName (
            &token, // token
            &buffer[0], // buffer
        )

        IF state & ARG_NAME_NONZERO AND NOT ignore THEN
            created : UBYTE

            arg := CAST TlLookupOrAllocateEntryHashTable (
                &hashtable, // hashtable
                SIZEOF LexMacroArgument, // entrysize
                &buffer[0], // key
                &created, // OUT created
            ) TO ^LexMacroArgument

            IF NOT created THEN
                LexTokenError ( &token,
                    "Macro argument name already used", 0, 0, 0 )
            END

            // Increment the length of the argument list by one.

            length^ += 1

            // Add to the caller's list of arguments.

            arg^.Next = NULLPTR
            arg^.Prev = arglisttail

            IF arglisttail THEN
                arglisttail^.Next = arg
            ELSE
                arglisthead^ = arg
            END

            arglisttail = arg
        END

        IF state & ARG_NAME_DONE THEN
            LEAVE
        END
    END
END

FN (LexDirectiveParseF) LexParseMacro ()

    // This directive defines a function macro.
    // First we consume the name token, then we consume the argument list, then
    // consume the contents.

    arglisthead : ^LexMacroArgument
    trashtoken : LexToken
    length : ULONG
    macro : ^LexMacro

    status := TlBumpAlloc (
        SIZEOF LexMacro, // bytes
        &macro, // OUT ptr
    )

    IF status THEN
        TlInternalError ( "Failed to allocate macro", 0, 0, 0 )
    END

    LexCollectDirectiveToken (
        &macro^.NameToken, // token
        &macro^.Name[0], // buffer
    )

    byte := LexNextNonWhitespaceCharacter ( &trashtoken )

    IF byte != '(' THEN
        LexTokenError ( &trashtoken, "Expected an open parenthesis", 0, 0, 0 )
    END

    IF LexFalseCount THEN
        // This macro definition is compiled out, so just collect the argument
        // list and contents and return. Allow the bump-allocated macro
        // structure to leak, this routine gets unruly if we try to avoid that.

        LexCollectMacroDefArgList (
            TRUE, // ignore
            &macro^.ArgListHead, // OUT arglisthead
            &length, // OUT length
        )

        contentsbuffer : TlDynamicBuffer

        TlInitializeDynamicBuffer ( &contentsbuffer )

        LexCollectValue (
            &trashtoken, // token
            &contentsbuffer, // buffer
        )

        TlUninitializeDynamicBuffer ( &contentsbuffer )

        LEAVE
    END

    LexCollectMacroDefArgList (
        FALSE, // ignore
        &macro^.ArgListHead, // OUT arglisthead
        &length, // OUT length
    )

    IF length == 0 THEN
        LexTokenError ( &macro^.NameToken,
            "Must have at least 1 argument", 0, 0, 0 )
    END

    oldmacro := CAST TlLookupSymbolTable (
        LexCurrentMacroScope, // symboltable
        &macro^.Name[0], // name
    ) TO ^LexMacro

    IF oldmacro THEN
        LexTokenError ( &macro^.NameToken, "Macro already defined", 0, 0, 0 )
    END

    macro^.IsFunctionMacro = TRUE

    LexCollectValue (
        &macro^.NameToken, // token
        &macro^.Contents, // buffer
    )

    TlInsertSymbolTable (
        LexCurrentMacroScope, // symboltable
        &macro^.Entry, // entry
        &macro^.Name[0], // name
    )
END

ENUM LexIfStatus : UBYTE
    IF_TAKEN,
    IF_NOT_YET_TAKEN,
    IF_BEING_TAKEN,
END

FN (LexDirectiveParseF) LexParseIf ()

    token : LexToken

    truthy := LexCollectValueNumeric (
        &token, // token
    )

    IF LexFalseCount THEN
        // We are inside a region that is already being compiled out, so push a
        // IF_TAKEN to indicate that this IF-END pair already had a taken
        // condition, which isn't true, but will prevent any ELSEIFs and ELSEs
        // from deciding to do anything.

        TlInsertDynamicBuffer ( &LexIfStack, IF_TAKEN )

        LexFalseCount += 1

        LEAVE
    END

    IF truthy THEN
        TlInsertDynamicBuffer ( &LexIfStack, IF_BEING_TAKEN )
    ELSE
        TlInsertDynamicBuffer ( &LexIfStack, IF_NOT_YET_TAKEN )

        // Increment the false count to cause the subsequent regions of source
        // text to be ignored.

        LexFalseCount += 1
    END
END

FN (LexDirectiveParseF) LexParseElse ()

    IF NOT LexIfStack.Count THEN
        LexStreamError ( "ELSE with no matching IF", 0, 0, 0 )
    END

    status := LexIfStack.Buffer[LexIfStack.Count - 1]

    IF status == IF_TAKEN THEN
        // A condition was already satisfied and the false count is biased.

        LEAVE
    END

    IF status == IF_BEING_TAKEN THEN
        // A true block was consumed and the following should be compiled out.

        LexIfStack.Buffer[LexIfStack.Count - 1] = IF_TAKEN
        LexFalseCount += 1

        LEAVE
    END

    // No conditions were taken yet, which means our block should be consumed.

    LexIfStack.Buffer[LexIfStack.Count - 1] = IF_BEING_TAKEN
    LexFalseCount -= 1
END

FN (LexDirectiveParseF) LexParseElseif ()

    IF NOT LexIfStack.Count THEN
        LexStreamError ( "ELSEIF with no matching IF", 0, 0, 0 )
    END

    token : LexToken

    truthy := LexCollectValueNumeric (
        &token, // token
    )

    status := LexIfStack.Buffer[LexIfStack.Count - 1]

    IF status == IF_TAKEN THEN
        // A condition was already satisfied and the false count is biased.

        LEAVE
    END

    IF status == IF_BEING_TAKEN THEN
        // A true block was consumed and the following should be compiled out.

        LexIfStack.Buffer[LexIfStack.Count - 1] = IF_TAKEN
        LexFalseCount += 1

        LEAVE
    END

    IF truthy THEN
        // No conditions were taken yet, and our condition was truthy, so our
        // block should be consumed.

        LexIfStack.Buffer[LexIfStack.Count - 1] = IF_BEING_TAKEN
        LexFalseCount -= 1
    ELSE
        // Our condition was not truthy, so leave the false count biased.

        LexIfStack.Buffer[LexIfStack.Count - 1] = IF_TAKEN
    END
END

FN (LexDirectiveParseF) LexParseEnd ()

    IF NOT LexIfStack.Count THEN
        LexStreamError ( "END with no matching IF", 0, 0, 0 )
    END

    status := TlPopDynamicBuffer ( &LexIfStack )

    IF status == IF_TAKEN OR status == IF_NOT_YET_TAKEN THEN
        // Un-bias the false count.

        LexFalseCount -= 1

        LEAVE
    END
END

FN (LexOperatorParseF) LexOperatorEquals (
    IN buffer : ^TlDynamicBuffer,
)

    // Consume two numeric values and compare them. Return 0 if false, 1 if
    // true.

    token : LexToken

    num1 := LexCollectValueNumeric ( &token )
    num2 := LexCollectValueNumeric ( &token )

    LexConsumeCloseParenthesis ()

    IF num1 == num2 THEN
        TlInsertNumberDynamicBuffer (
            buffer, // array
            1, // number
            10, // base
        )
    ELSE
        TlInsertNumberDynamicBuffer (
            buffer, // array
            0, // number
            10, // base
        )
    END

    TlInsertDynamicBuffer (
        buffer, // array
        0, // byte
    )
END

FN (LexOperatorParseF) LexOperatorLteq (
    IN buffer : ^TlDynamicBuffer,
)

    // Consume two numeric values and compare them. Return 0 if false, 1 if
    // true.

    token : LexToken

    num1 := LexCollectValueNumeric ( &token )
    num2 := LexCollectValueNumeric ( &token )

    LexConsumeCloseParenthesis ()

    IF num1 <= num2 THEN
        TlInsertNumberDynamicBuffer (
            buffer, // array
            1, // number
            10, // base
        )
    ELSE
        TlInsertNumberDynamicBuffer (
            buffer, // array
            0, // number
            10, // base
        )
    END

    TlInsertDynamicBuffer (
        buffer, // array
        0, // byte
    )
END

FN (LexOperatorParseF) LexOperatorGteq (
    IN buffer : ^TlDynamicBuffer,
)

    // Consume two numeric values and compare them. Return 0 if false, 1 if
    // true.

    token : LexToken

    num1 := LexCollectValueNumeric ( &token )
    num2 := LexCollectValueNumeric ( &token )

    LexConsumeCloseParenthesis ()

    IF num1 >= num2 THEN
        TlInsertNumberDynamicBuffer (
            buffer, // array
            1, // number
            10, // base
        )
    ELSE
        TlInsertNumberDynamicBuffer (
            buffer, // array
            0, // number
            10, // base
        )
    END

    TlInsertDynamicBuffer (
        buffer, // array
        0, // byte
    )
END

FN (LexOperatorParseF) LexOperatorNeq (
    IN buffer : ^TlDynamicBuffer,
)

    // Consume two numeric values and compare them. Return 0 if false, 1 if
    // true.

    token : LexToken

    num1 := LexCollectValueNumeric ( &token )
    num2 := LexCollectValueNumeric ( &token )

    LexConsumeCloseParenthesis ()

    IF num1 != num2 THEN
        TlInsertNumberDynamicBuffer (
            buffer, // array
            1, // number
            10, // base
        )
    ELSE
        TlInsertNumberDynamicBuffer (
            buffer, // array
            0, // number
            10, // base
        )
    END

    TlInsertDynamicBuffer (
        buffer, // array
        0, // byte
    )
END

FN (LexOperatorParseF) LexOperatorLt (
    IN buffer : ^TlDynamicBuffer,
)

    // Consume two numeric values and compare them. Return 0 if false, 1 if
    // true.

    token : LexToken

    num1 := LexCollectValueNumeric ( &token )
    num2 := LexCollectValueNumeric ( &token )

    LexConsumeCloseParenthesis ()

    IF num1 < num2 THEN
        TlInsertNumberDynamicBuffer (
            buffer, // array
            1, // number
            10, // base
        )
    ELSE
        TlInsertNumberDynamicBuffer (
            buffer, // array
            0, // number
            10, // base
        )
    END

    TlInsertDynamicBuffer (
        buffer, // array
        0, // byte
    )
END

FN (LexOperatorParseF) LexOperatorGt (
    IN buffer : ^TlDynamicBuffer,
)

    // Consume two numeric values and compare them. Return 0 if false, 1 if
    // true.

    token : LexToken

    num1 := LexCollectValueNumeric ( &token )
    num2 := LexCollectValueNumeric ( &token )

    LexConsumeCloseParenthesis ()

    IF num1 > num2 THEN
        TlInsertNumberDynamicBuffer (
            buffer, // array
            1, // number
            10, // base
        )
    ELSE
        TlInsertNumberDynamicBuffer (
            buffer, // array
            0, // number
            10, // base
        )
    END

    TlInsertDynamicBuffer (
        buffer, // array
        0, // byte
    )
END

FN (LexOperatorParseF) LexOperatorAdd (
    IN buffer : ^TlDynamicBuffer,
)

    // Consume two numeric values and operate on them.

    token : LexToken

    num1 := LexCollectValueNumeric ( &token )
    num2 := LexCollectValueNumeric ( &token )

    LexConsumeCloseParenthesis ()

    TlInsertNumberDynamicBuffer (
        buffer, // array
        num1 + num2, // number
        10, // base
    )

    TlInsertDynamicBuffer (
        buffer, // array
        0, // byte
    )
END

FN (LexOperatorParseF) LexOperatorSub (
    IN buffer : ^TlDynamicBuffer,
)

    // Consume two numeric values and operate on them.

    token : LexToken

    num1 := LexCollectValueNumeric ( &token )
    num2 := LexCollectValueNumeric ( &token )

    LexConsumeCloseParenthesis ()

    TlInsertNumberDynamicBuffer (
        buffer, // array
        num1 - num2, // number
        10, // base
    )

    TlInsertDynamicBuffer (
        buffer, // array
        0, // byte
    )
END

FN (LexOperatorParseF) LexOperatorMul (
    IN buffer : ^TlDynamicBuffer,
)

    // Consume two numeric values and operate on them.

    token : LexToken

    num1 := LexCollectValueNumeric ( &token )
    num2 := LexCollectValueNumeric ( &token )

    LexConsumeCloseParenthesis ()

    TlInsertNumberDynamicBuffer (
        buffer, // array
        num1 * num2, // number
        10, // base
    )

    TlInsertDynamicBuffer (
        buffer, // array
        0, // byte
    )
END

FN (LexOperatorParseF) LexOperatorDiv (
    IN buffer : ^TlDynamicBuffer,
)

    // Consume two numeric values and operate on them.

    token : LexToken

    num1 := LexCollectValueNumeric ( &token )
    num2 := LexCollectValueNumeric ( &token )

    LexConsumeCloseParenthesis ()

    TlInsertNumberDynamicBuffer (
        buffer, // array
        num1 / num2, // number
        10, // base
    )

    TlInsertDynamicBuffer (
        buffer, // array
        0, // byte
    )
END

FN (LexOperatorParseF) LexOperatorLsh (
    IN buffer : ^TlDynamicBuffer,
)

    // Consume two numeric values and operate on them.

    token : LexToken

    num1 := LexCollectValueNumeric ( &token )
    num2 := LexCollectValueNumeric ( &token )

    LexConsumeCloseParenthesis ()

    TlInsertNumberDynamicBuffer (
        buffer, // array
        num1 << num2, // number
        10, // base
    )

    TlInsertDynamicBuffer (
        buffer, // array
        0, // byte
    )
END

FN (LexOperatorParseF) LexOperatorRsh (
    IN buffer : ^TlDynamicBuffer,
)

    // Consume two numeric values and operate on them.

    token : LexToken

    num1 := LexCollectValueNumeric ( &token )
    num2 := LexCollectValueNumeric ( &token )

    LexConsumeCloseParenthesis ()

    TlInsertNumberDynamicBuffer (
        buffer, // array
        num1 >> num2, // number
        10, // base
    )

    TlInsertDynamicBuffer (
        buffer, // array
        0, // byte
    )
END

FN (LexOperatorParseF) LexOperatorStrcat (
    IN buffer : ^TlDynamicBuffer,
)

    // Append two strings.

    token : LexToken

    // Consume the first value into the buffer.

    LexCollectValue (
        &token, // token
        buffer, // buffer
    )

    // Strip the null terminator.

    TlPopDynamicBuffer ( buffer )

    // Consume the second value into the buffer.

    LexCollectValue (
        &token, // token
        buffer, // buffer
    )

    LexConsumeCloseParenthesis ()
END

FN (LexOperatorParseF) LexOperatorStrcmp (
    IN buffer : ^TlDynamicBuffer,
)

    // Compare two strings. Return 1 if equal, otherwise 0.

    token : LexToken
    str1 : TlDynamicBuffer
    str2 : TlDynamicBuffer

    TlInitializeDynamicBuffer ( &str1 )
    TlInitializeDynamicBuffer ( &str2 )

    // Consume the first value into the buffer.

    LexCollectValue (
        &token, // token
        &str1, // buffer
    )

    // Consume the second value.

    LexCollectValue (
        &token, // token
        &str2, // buffer
    )

    TlUninitializeDynamicBuffer ( &str1 )
    TlUninitializeDynamicBuffer ( &str2 )

    LexConsumeCloseParenthesis ()

    IF TlCompareString ( str1.Buffer, str2.Buffer ) == 0 THEN
        TlInsertNumberDynamicBuffer (
            buffer, // array
            1, // number
            10, // base
        )
    ELSE
        TlInsertNumberDynamicBuffer (
            buffer, // array
            0, // number
            10, // base
        )
    END

    TlInsertDynamicBuffer (
        buffer, // array
        0, // byte
    )
END

FN (LexOperatorParseF) LexOperatorNot (
    IN buffer : ^TlDynamicBuffer,
)

    // Return the logical inverse of the value.

    token : LexToken

    num1 := LexCollectValueNumeric ( &token )

    LexConsumeCloseParenthesis ()

    IF num1 THEN
        TlInsertNumberDynamicBuffer (
            buffer, // array
            0, // number
            10, // base
        )
    ELSE
        TlInsertNumberDynamicBuffer (
            buffer, // array
            1, // number
            10, // base
        )
    END

    TlInsertDynamicBuffer (
        buffer, // array
        0, // byte
    )
END

FN (LexOperatorParseF) LexOperatorBitNot (
    IN buffer : ^TlDynamicBuffer,
)

    // Return the bitwise inverse of the value.

    token : LexToken

    num1 := LexCollectValueNumeric ( &token )

    LexConsumeCloseParenthesis ()

    TlInsertNumberDynamicBuffer (
        buffer, // array
        ~num1, // number
        10, // base
    )

    TlInsertDynamicBuffer (
        buffer, // array
        0, // byte
    )
END

FN (LexOperatorParseF) LexOperatorBitOr (
    IN buffer : ^TlDynamicBuffer,
)

    // Consume two numeric values and operate on them.

    token : LexToken

    num1 := LexCollectValueNumeric ( &token )
    num2 := LexCollectValueNumeric ( &token )

    LexConsumeCloseParenthesis ()

    TlInsertNumberDynamicBuffer (
        buffer, // array
        num1 | num2, // number
        10, // base
    )

    TlInsertDynamicBuffer (
        buffer, // array
        0, // byte
    )
END

FN (LexOperatorParseF) LexOperatorBitXor (
    IN buffer : ^TlDynamicBuffer,
)

    // Consume two numeric values and operate on them.

    token : LexToken

    num1 := LexCollectValueNumeric ( &token )
    num2 := LexCollectValueNumeric ( &token )

    LexConsumeCloseParenthesis ()

    TlInsertNumberDynamicBuffer (
        buffer, // array
        num1 $ num2, // number
        10, // base
    )

    TlInsertDynamicBuffer (
        buffer, // array
        0, // byte
    )
END

FN (LexOperatorParseF) LexOperatorBitAnd (
    IN buffer : ^TlDynamicBuffer,
)

    // Consume two numeric values and operate on them.

    token : LexToken

    num1 := LexCollectValueNumeric ( &token )
    num2 := LexCollectValueNumeric ( &token )

    LexConsumeCloseParenthesis ()

    TlInsertNumberDynamicBuffer (
        buffer, // array
        num1 & num2, // number
        10, // base
    )

    TlInsertDynamicBuffer (
        buffer, // array
        0, // byte
    )
END