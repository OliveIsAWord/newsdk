//
// Lexer.
//

#INCLUDE "<inc>/Frontend.jh"
#INCLUDE "<inc>/Runtime.jh"
#INCLUDE "<inc>/Lexer.jh"

// The "engine" of the lexer, the bit that provides the character stream,
// operates by stacking and unstacking source text streams. Each stream has a
// filename and a current line number associated with it, which are ultimately
// used to generate useful diagnostic messages. Streams are associated with
// include files, and also with preprocessor macro expansion.

LexCharTreatment : LexCharBehavior[256] = {
	[' ']  = CHAR_WHITESPACE,
	['\n'] = CHAR_WHITESPACE,
	['\t'] = CHAR_WHITESPACE,

	['^'] = CHAR_SPLIT,
	['('] = CHAR_SPLIT,
	[')'] = CHAR_SPLIT,
	['~'] = CHAR_SPLIT,
	[','] = CHAR_SPLIT,
	['['] = CHAR_SPLIT,
	[']'] = CHAR_SPLIT,
	[':'] = CHAR_SPLIT,
	['{'] = CHAR_SPLIT,
	['}'] = CHAR_SPLIT,

	['='] = CHAR_COALESCE,
	['&'] = CHAR_COALESCE,
	['|'] = CHAR_COALESCE,
	['!'] = CHAR_COALESCE,
	['<'] = CHAR_COALESCE,
	['>'] = CHAR_COALESCE,
	['+'] = CHAR_COALESCE,
	['-'] = CHAR_COALESCE,
	['*'] = CHAR_COALESCE,
	['/'] = CHAR_COALESCE,
	['%'] = CHAR_COALESCE,
	['.'] = CHAR_COALESCE,
	['@'] = CHAR_COALESCE,
	['$'] = CHAR_COALESCE,

	// Since CHAR_NORMAL is the first field in the enum, it is guaranteed to
	// be zero in value, so we don't have to explicitly set all the other
	// character behaviors to it, since any non-defined fields here will also
	// be zero.
}

LexPutbackStack : LexToken[LEX_PUTBACK_STACK_DEPTH]

LexCurrentStream : ^LexStream = 0
LexCurrentMacroScope : ^TlSymbolTable = 0
LexFalseCount : ULONG = 0
LexPutbackStackPtr : ULONG = 0

STRUCT LexKeyword
	Entry : TlHashTableEntry,
	Type : LexTokenType,
	Subtype : LexTokenSubtype,
END

LexKeywordHashTable : TlHashTable

LexKeywordBumpArray : LexKeyword[128]
LexKeywordBumpIndex := 0

FN LexKeywordInsert (
	IN name : ^UBYTE,
	IN type : LexTokenType,
	IN subtype : LexTokenSubtype,
)

	// Insert the keyword into the keyword hash table.
	// This is done every time the compiler is invoked so it should be VERY
	// fast. To this end we completely avoid dynamic allocation with this silly
	// keyword structure bump allocator. The hash table package does no dynamic
	// allocation, nor does it do any string copies (though it does iterate the
	// string to calculate the hash), so this should all be quite speedy.

	keyword := &LexKeywordBumpArray[LexKeywordBumpIndex]
	LexKeywordBumpIndex += 1

	keyword^.Type = type
	keyword^.Subtype = subtype

	TlHashTableInsert (
		&LexKeywordHashTable, // hashtable
		&keyword^.Entry, // entry
		name, // key
	)
END

FN LexInitialize () : TlStatus

	// Create the root file stream.

	filestream : ^LexFileStream

	status := LexFileStreamCreate (
		FeInputFileHandle, // handle
		FeInputFile, // filename
		&filestream, // OUT filestream
	)

	IF status THEN
		RETURN status
	END

	LexStreamPush ( CAST filestream TO ^LexStream )

	// Create the root macro scope.

	status = TlSymbolTableCreate (
		0, // outerscope
		&LexMacroDelete, // deletefunc
		&LexCurrentMacroScope, // OUT symboltable
	)

	IF status THEN
		RETURN status
	END

	// Initialize keyword hash table.

	TlHashTableInitialize ( &LexKeywordHashTable )

	LexKeywordInsert ( "AND", TOKEN_OPER, TOKEN_AND )
	LexKeywordInsert ( "BEGIN", TOKEN_STATEMENT, TOKEN_BEGIN )
	LexKeywordInsert ( "BREAK", TOKEN_STATEMENT, TOKEN_BREAK )
	LexKeywordInsert ( "BYTE", TOKEN_PTYPE, TOKEN_BYTE )
	LexKeywordInsert ( "CAST", TOKEN_OPER, TOKEN_CAST )
	LexKeywordInsert ( "CONST", TOKEN_DECL, TOKEN_CONST )
	LexKeywordInsert ( "CONTINUE", TOKEN_STATEMENT, TOKEN_CONTINUE )
	LexKeywordInsert ( "DO", TOKEN_OTHER, TOKEN_DO )
	LexKeywordInsert ( "ELSE", TOKEN_STATEMENT, TOKEN_ELSE )
	LexKeywordInsert ( "ELSEIF", TOKEN_STATEMENT, TOKEN_ELSEIF )
	LexKeywordInsert ( "END", TOKEN_STATEMENT, TOKEN_END )
	LexKeywordInsert ( "ENUM", TOKEN_DECL, TOKEN_ENUM )
	LexKeywordInsert ( "EXTERN", TOKEN_DECL, TOKEN_EXTERN )
	LexKeywordInsert ( "FALSE", TOKEN_VALUE, TOKEN_FALSE )
	LexKeywordInsert ( "FN", TOKEN_DECL, TOKEN_FN )
	LexKeywordInsert ( "FNPTR", TOKEN_DECL, TOKEN_FNPTR )
	LexKeywordInsert ( "FNSECTION", TOKEN_STATEMENT, TOKEN_FNSECTION )
	LexKeywordInsert ( "GOTO", TOKEN_STATEMENT, TOKEN_GOTO )
	LexKeywordInsert ( "IF", TOKEN_STATEMENT, TOKEN_IF )
	LexKeywordInsert ( "IN", TOKEN_ARGSPEC, TOKEN_IN )
	LexKeywordInsert ( "INT", TOKEN_PTYPE, TOKEN_INT )
	LexKeywordInsert ( "LEAVE", TOKEN_STATEMENT, TOKEN_LEAVE )
	LexKeywordInsert ( "LONG", TOKEN_PTYPE, TOKEN_LONG )
	LexKeywordInsert ( "NOT", TOKEN_OPER, TOKEN_NOT )
	LexKeywordInsert ( "NULL", TOKEN_VALUE, TOKEN_NULL )
	LexKeywordInsert ( "NULLPTR", TOKEN_VALUE, TOKEN_NULLPTR )
	LexKeywordInsert ( "OR", TOKEN_OPER, TOKEN_OR )
	LexKeywordInsert ( "OUT", TOKEN_ARGSPEC, TOKEN_OUT )
	LexKeywordInsert ( "PACKED", TOKEN_OTHER, TOKEN_PACKED )
	LexKeywordInsert ( "PUBLIC", TOKEN_DECL, TOKEN_PUBLIC )
	LexKeywordInsert ( "RETURN", TOKEN_STATEMENT, TOKEN_RETURN )
	LexKeywordInsert ( "SECTION", TOKEN_DECL, TOKEN_SECTION )
	LexKeywordInsert ( "SIZEOF", TOKEN_VALUE, TOKEN_SIZEOF )
	LexKeywordInsert ( "SIZEOFVALUE", TOKEN_OPER, TOKEN_SIZEOFVALUE )
	LexKeywordInsert ( "STRUCT", TOKEN_DECL, TOKEN_STRUCT )
	LexKeywordInsert ( "THEN", TOKEN_OTHER, TOKEN_THEN )
	LexKeywordInsert ( "TO", TOKEN_OTHER, TOKEN_TO )
	LexKeywordInsert ( "TRUE", TOKEN_VALUE, TOKEN_TRUE )
	LexKeywordInsert ( "TYPE", TOKEN_DECL, TOKEN_TYPE )
	LexKeywordInsert ( "UBYTE", TOKEN_PTYPE, TOKEN_UBYTE )
	LexKeywordInsert ( "UINT", TOKEN_PTYPE, TOKEN_UINT )
	LexKeywordInsert ( "ULONG", TOKEN_PTYPE, TOKEN_ULONG )
	LexKeywordInsert ( "UNION", TOKEN_DECL, TOKEN_UNION )
	LexKeywordInsert ( "VOID", TOKEN_PTYPE, TOKEN_VOID )
	LexKeywordInsert ( "WHILE", TOKEN_STATEMENT, TOKEN_WHILE )

	LexKeywordInsert ( "(", TOKEN_LPAREN, NULL )
	LexKeywordInsert ( ")", TOKEN_RPAREN, NULL )
	LexKeywordInsert ( "[", TOKEN_LBRACKET, NULL )
	LexKeywordInsert ( "]", TOKEN_RBRACKET, NULL )
	LexKeywordInsert ( "^", TOKEN_CARET, NULL )
	LexKeywordInsert ( ":", TOKEN_COLON, NULL )
	LexKeywordInsert ( "{", TOKEN_LBRACE, NULL )
	LexKeywordInsert ( "}", TOKEN_RBRACE, NULL )

	LexKeywordInsert ( "==", TOKEN_OPER, TOKEN_EQUIV )
	LexKeywordInsert ( "!=", TOKEN_OPER, TOKEN_NOTEQUIV )
	LexKeywordInsert ( "&", TOKEN_OPER, TOKEN_BITAND )
	LexKeywordInsert ( "|", TOKEN_OPER, TOKEN_BITOR )
	LexKeywordInsert ( "<", TOKEN_OPER, TOKEN_LESSTHAN )
	LexKeywordInsert ( ">", TOKEN_OPER, TOKEN_GREATERTHAN )
	LexKeywordInsert ( "<=", TOKEN_OPER, TOKEN_LTEQ )
	LexKeywordInsert ( ">=", TOKEN_OPER, TOKEN_GTEQ )
	LexKeywordInsert ( "+", TOKEN_OPER, TOKEN_PLUS )
	LexKeywordInsert ( "-", TOKEN_OPER, TOKEN_MINUS )
	LexKeywordInsert ( "/", TOKEN_OPER, TOKEN_DIVIDE )
	LexKeywordInsert ( "%", TOKEN_OPER, TOKEN_MODULO )
	LexKeywordInsert ( ".", TOKEN_OPER, TOKEN_DOT )
	LexKeywordInsert ( "@", TOKEN_STATEMENT, TOKEN_LABEL )
	LexKeywordInsert ( "$", TOKEN_OPER, TOKEN_BITXOR )
	LexKeywordInsert ( "<<", TOKEN_OPER, TOKEN_LEFTSHIFT )
	LexKeywordInsert ( ">>", TOKEN_OPER, TOKEN_RIGHTSHIFT )
	LexKeywordInsert ( "~", TOKEN_OPER, TOKEN_BITNOT )

	LexKeywordInsert ( "=", TOKEN_ASSIGN, TOKEN_EQUALS )
	LexKeywordInsert ( "+=", TOKEN_ASSIGN, TOKEN_PLUSEQUALS )
	LexKeywordInsert ( "-=", TOKEN_ASSIGN, TOKEN_MINUSEQUALS )
	LexKeywordInsert ( "*=", TOKEN_ASSIGN, TOKEN_MULEQUALS )
	LexKeywordInsert ( "/=", TOKEN_ASSIGN, TOKEN_DIVEQUALS )
	LexKeywordInsert ( "%=", TOKEN_ASSIGN, TOKEN_MODEQUALS )
	LexKeywordInsert ( "&=", TOKEN_ASSIGN, TOKEN_ANDEQUALS )
	LexKeywordInsert ( "|=", TOKEN_ASSIGN, TOKEN_OREQUALS )
	LexKeywordInsert ( "$=", TOKEN_ASSIGN, TOKEN_XOREQUALS )
	LexKeywordInsert ( "<<=", TOKEN_ASSIGN, TOKEN_LSHEQUALS )
	LexKeywordInsert ( ">>=", TOKEN_ASSIGN, TOKEN_RSHEQUALS )

	TlHashTableSummarize ( &LexKeywordHashTable )

	byte := LexGetCharacter ( )

	WHILE byte DO
		TlPrintCharacter ( byte )

		byte = LexGetCharacter ( )
	END

	RETURN status
END

FN (TlHashTableEnumF) LexMacroDelete (
	IN entry : ^TlHashTableEntry,
)

	TlFree ( entry )
END

LexCharacterBackslash := FALSE
LexCharacterInString := FALSE
LexCharacterInLiteral := FALSE
LexCharacterPutback : UBYTE = 0

// LexCharacterNewlineSeen is initialized to TRUE so that the first character
// of the stream is correctly identified as the beginning of a line.

LexCharacterNewlineSeen := TRUE

FN LexGetCharacter () : UBYTE

	// Return the next character in the source stream. Omits comments and text
	// that is killed by the "preprocessor", and notices preprocessor
	// directives, which it ships off to a special little interpreter.

	byte : UBYTE

	comment := FALSE

	WHILE TRUE DO
		IF LexCharacterPutback THEN
			byte = LexCharacterPutback
			LexCharacterPutback = 0
		ELSE
			byte = LexStreamNextCharacter ()

			IF NOT byte THEN
				// EOF has been reached.

				BREAK
			END
		END

		// We care about backslashes and about knowing whether we're in a
		// string or not in this routine, because otherwise we will
		// mis-identify things as comments or directives that aren't.

		IF comment THEN
			IF byte != '\n' THEN
				CONTINUE
			END

			comment = FALSE

			// Make sure this newline is seen by the higher level code,
			// otherwise a token that is immediately followed by a comment
			// with no interfering whitespace may not terminate properly.

		ELSEIF LexCharacterInString THEN
			LexCharacterInString = NOT (byte == '\"')

		ELSEIF LexCharacterInLiteral THEN
			LexCharacterInLiteral = NOT (byte == 0x27) // single-quote

		ELSEIF byte == '/' THEN
			// We have to figure out if this is a comment or not. This
			// requires looking at the next character and seeing if it is also
			// a forward slash character. If it is, we set comment to true. If
			// it isn't, we pass this forward slash along and set putback to
			// the value of the character we peeked, causing it to be returned
			// on the next call.

			nextbyte := LexStreamNextCharacter ()

			IF nextbyte == '/' THEN
				comment = TRUE

				CONTINUE
			END

			LexCharacterPutback = nextbyte

		ELSEIF LexCharacterBackslash THEN
			LexCharacterBackslash = FALSE

		ELSEIF byte == '\\' THEN
			LexCharacterBackslash = TRUE

		ELSEIF byte == '\"' THEN
			LexCharacterInString = TRUE

		ELSEIF byte == 0x27 THEN // single-quote
			LexCharacterInLiteral = TRUE

		ELSEIF LexCharacterNewlineSeen AND byte == '#' THEN
			// We found a preprocessor directive! We dispatch to
			// the preprocessor regardless of the value of the false count.
			// This gives it an opportunity to manipulate the false count, but
			// it must be sure to ignore directives that aren't relevant.

			LexParseDirective ()

			// The preprocessor consumed the newline character terminating the
			// directive, so we return one here for good measure.

			byte = '\n'
		END

		LexCharacterNewlineSeen = byte == '\n'

		IF LexFalseCount THEN
			// A non-zero false count causes all characters to be ignored
			// until this situation is resolved by a preprocessor directive.
			// This is used for conditional compilation.

			CONTINUE
		END

		BREAK
	END

	RETURN byte
END

FN LexGetToken (
	IN token : ^LexToken,
)

	
END